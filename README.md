# Web Crawler 🕸️
## Clean Code - Alpen Adria Universität Klagenfurt 

## Overview 🌐
This project implements a **web crawler** in Java that generates a compact overview of a given website and its linked pages. The crawler collects information such as headings and URLs from a website, ensuring that only the specified **depth** and **domains** are crawled.

- Broken links are **highlighted**.
- The results are saved in a **markdown file**.
- **Unit tests** are included to ensure proper functionality. 

---

## How to Build, Run, and Test ⚙️

### Prerequisites 
- **Java 11** or higher installed 
- **Maven** installed (for dependency management and building the project) 
- **JUnit** for unit testing 
- **jsoup** library for parsing HTML (included in `pom.xml`) 
- A modern IDE (Eclipse, IntelliJ IDEA, Visual Studio Code, etc.)


### 1. Clone the Repository 🚢

Clone the project from GitHub (or GitLab/BitBucket):

```bash
git clone https://github.com/yourusername/web-crawler.git
cd web-crawler ```
